=== Host: ramses16313 ===
GPU 0: NVIDIA H100 (UUID: GPU-265a1f7a-2d77-1a76-040d-ae57b96e5e0c)
torch 2.2.1 | cuda True
wandb 0.16.6
[2026-02-08 16:12:12,741] GPU : NVIDIA H100. CUDA: 12.1.
[2026-02-08 16:12:12,747] Platform: linux, Python: 3.11.8, PyTorch: 2.2.1
[2026-02-08 16:12:12,747] CPUs: 16, GPUs: 1 on ramses16313.
[2026-02-08 16:12:12,747] Seeding with random seed 2600980116 on rank 0.
[2026-02-08 16:12:16,339] --------------------------------------------------------------
[2026-02-08 16:12:16,339] --------------Launching pretraining run! ---------------------
[2026-02-08 16:12:16,344] arch:
  architectures:
  - ScriptableCrammedBERT
  num_transformer_layers: 16
  hidden_size: 768
  intermed_size: 3072
  hidden_dropout_prob: 0.1
  norm: LayerNorm
  norm_eps: 1.0e-12
  norm_scheme: pre
  nonlin: GELUglu
  tie_weights: true
  decoder_bias: false
  sparse_prediction: 0.25
  loss: cross-entropy
  objective_layout: MLM
  embedding:
    vocab_size: null
    pos_embedding: scaled-sinusoidal
    dropout_prob: 0.1
    pad_token_id: 0
    max_seq_length: 128
    embedding_dim: 768
    normalization: true
    stable_low_precision: false
  attention:
    type: self-attention
    causal_attention: false
    num_attention_heads: 12
    dropout_prob: 0.1
    skip_output_projection: false
    qkv_bias: false
    rotary_embedding: false
    seq_op_in_fp32: false
    sequence_op: torch-softmax
  init:
    type: normal
    std: 0.02
  ffn_layer_frequency: 1
  skip_head_transform: true
  use_bias: false
  final_norm: true
  num_labels: null
  classification_head:
    pooler: avg
    include_ff_layer: true
    head_dim: 1024
    nonlin: Tanh
    classifier_dropout: 0.1
data:
  name: pile-readymade
  sources:
    hub:
      provider: hub
  hf_location: JonasGeiping/the_pile_WordPiecex32768_2efdb9d060d1ae95faf952ec1a50f020
  streaming: true
  vocab_size: 32768
  seq_length: 128
impl:
  path: /home/group.kurse/jnoow006/cramming/outputs/data
  local_staging_dir: null
  forbid_dataset_preprocessing: false
  temporary_corpus: false
  max_raw_chunk_size: 8000000.0
  print_loss_every_nth_step: 1000
  save_intermediate_checkpoints: false
  save_every_nth_step: 10000
  resume_run_after_preempt: false
  troubleshoot_strategy: none
  early_termination:
    enabled: false
    budget: 3
    loss_threshold: 6.0
  microbatch_size: 1024
  threads: 16
  benchmark: true
  deterministic: false
  non_blocking: true
  tf32_allowed: true
  matmul_precision: high
  pad_to_multiple_of: 8
  shuffle_in_dataloader: false
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: true
  default_precision: float
  dist_backend: nccl
  sharing_strategy: null
  enable_huggingface_offline_mode: false
  local_rank: 0
  push_to_huggingface_hub: false
  hf_directoy_name: test-crammedBERT-c5
  add_env_variables: null
  name: torch-default
  mixed_precision: true
  grad_scaling: true
  mixed_precision_target_dtype: float16
  zero_redundancy_optimizer: false
  broadcast_buffers: false
  bucket_cap_mb: 25
  gradient_as_bucket_view: true
  static_graph: false
  foreach_optimizer: false
  compile_torch: false
  mode: null
  dynamic: false
  fullgraph: false
  backend: inductor
  _inductor_vars:
    max_autotune_gemm: true
    max_autotune_pointwise: false
    triton:
      cudagraphs: true
      cudagraph_trees: false
    permute_fusion: true
    shape_padding: true
  enable_mem_efficient_sdp: true
  enable_math_sdp: true
  enable_flash_sdp: true
wandb:
  enabled: true
  entity: null
  project: cramming
  tags: []
train:
  optim:
    type: AdamW
    lr: 0.001
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-12
    weight_decay: 0.01
    amsgrad: false
    fused: null
  optim_mod:
    name: none
  name: bert-o4
  limited_decay_keys:
  - bias
  - LayerNorm.bias
  - LayerNorm.weight
  - norm
  warmup_steps: 0
  cooldown_steps: 0
  steps: 900000
  scheduler: budget-triangle2
  batch_size: 8192
  batch_size_ramp: 0.6
  gradient_clipping: 0.5
  pretrain_in_train_mode: false
  objective:
    name: masked-lm
    mlm_probability: 0.25
    use_80_20_rule: true
    disable_mlm: false
    token_drop: 0.0
  reverse_dataset_order: false
  budget: 8
base_dir: /home/group.kurse/jnoow006/cramming/outputs
seed: 2600980116
name: berto4_8h_H100
budget: 8
dryrun: false
original_cwd: /home/group.kurse/jnoow006/cramming

[2026-02-08 16:12:17,514] Model with architecture ScriptableCrammedBERT loaded with 119,589,889 parameters.
[2026-02-08 16:20:53,528] Train loss 3.2678 at step 1000 with lr 0.00027. [Avg: 4.6072]  Perf: 0.5135s per step (255233t/s). Estimated Total Train: 5 days, 8:23:05.363746.
[2026-02-08 16:29:25,061] Train loss 2.7797 at step 2000 with lr 0.00029. [Avg: 2.9584]  Perf: 0.5115s per step (256234t/s). Estimated Total Train: 5 days, 7:52:58.387856.
[2026-02-08 16:37:56,775] Train loss 2.7255 at step 3000 with lr 0.00030. [Avg: 2.7442]  Perf: 0.5117s per step (256143t/s). Estimated Total Train: 5 days, 7:55:42.192507.
[2026-02-08 16:46:28,637] Train loss 2.7978 at step 4000 with lr 0.00032. [Avg: 2.7044]  Perf: 0.5119s per step (256070t/s). Estimated Total Train: 5 days, 7:57:54.446225.
[2026-02-08 16:54:58,311] Train loss 2.6926 at step 5000 with lr 0.00034. [Avg: 2.6824]  Perf: 0.5097s per step (257168t/s). Estimated Total Train: 5 days, 7:25:06.643367.
[2026-02-08 17:03:27,354] Train loss 2.6478 at step 6000 with lr 0.00036. [Avg: 2.6428]  Perf: 0.5090s per step (257488t/s). Estimated Total Train: 5 days, 7:15:37.851119.
[2026-02-08 17:11:56,356] Train loss 2.6074 at step 7000 with lr 0.00037. [Avg: 2.6467]  Perf: 0.5090s per step (257508t/s). Estimated Total Train: 5 days, 7:15:00.923109.
[2026-02-08 17:20:25,476] Train loss 2.5676 at step 8000 with lr 0.00039. [Avg: 2.5929]  Perf: 0.5091s per step (257448t/s). Estimated Total Train: 5 days, 7:16:47.442212.
[2026-02-08 17:28:54,059] Train loss 2.5866 at step 9000 with lr 0.00041. [Avg: 2.6226]  Perf: 0.5086s per step (257721t/s). Estimated Total Train: 5 days, 7:08:42.958231.
[2026-02-08 17:37:22,276] Train loss 2.6205 at step 10000 with lr 0.00043. [Avg: 2.5808]  Perf: 0.5082s per step (257906t/s). Estimated Total Train: 5 days, 7:03:14.771290.
[2026-02-08 17:45:50,359] Train loss 2.4870 at step 11000 with lr 0.00044. [Avg: 2.5475]  Perf: 0.5081s per step (257974t/s). Estimated Total Train: 5 days, 7:01:13.805594.
[2026-02-08 17:54:18,432] Train loss 2.5133 at step 12000 with lr 0.00046. [Avg: 2.5225]  Perf: 0.5081s per step (257979t/s). Estimated Total Train: 5 days, 7:01:05.115881.
[2026-02-08 18:02:46,354] Train loss 2.4677 at step 13000 with lr 0.00048. [Avg: 2.5343]  Perf: 0.5079s per step (258056t/s). Estimated Total Train: 5 days, 6:58:48.597665.
[2026-02-08 18:11:14,012] Train loss 2.4727 at step 14000 with lr 0.00050. [Avg: 2.5350]  Perf: 0.5077s per step (258190t/s). Estimated Total Train: 5 days, 6:54:51.412067.
[2026-02-08 18:19:41,690] Train loss 2.4582 at step 15000 with lr 0.00052. [Avg: 2.5097]  Perf: 0.5077s per step (258180t/s). Estimated Total Train: 5 days, 6:55:09.584141.
[2026-02-08 18:28:09,509] Train loss 2.4555 at step 16000 with lr 0.00053. [Avg: 2.4884]  Perf: 0.5078s per step (258108t/s). Estimated Total Train: 5 days, 6:57:15.865974.
[2026-02-08 18:36:37,290] Train loss 2.4469 at step 17000 with lr 0.00055. [Avg: 2.4682]  Perf: 0.5078s per step (258128t/s). Estimated Total Train: 5 days, 6:56:41.981306.
[2026-02-08 18:45:04,808] Train loss 2.4621 at step 18000 with lr 0.00057. [Avg: 2.4448]  Perf: 0.5075s per step (258261t/s). Estimated Total Train: 5 days, 6:52:45.463901.
[2026-02-08 18:53:32,780] Train loss 2.4676 at step 19000 with lr 0.00059. [Avg: 2.4277]  Perf: 0.5080s per step (258030t/s). Estimated Total Train: 5 days, 6:59:34.400353.
[2026-02-08 19:02:00,002] Train loss 2.4574 at step 20000 with lr 0.00060. [Avg: 2.4350]  Perf: 0.5072s per step (258412t/s). Estimated Total Train: 5 days, 6:48:18.466730.
[2026-02-08 19:10:27,263] Train loss 2.5117 at step 21000 with lr 0.00062. [Avg: 2.4497]  Perf: 0.5073s per step (258392t/s). Estimated Total Train: 5 days, 6:48:53.859015.
[2026-02-08 19:18:54,534] Train loss 2.3975 at step 22000 with lr 0.00064. [Avg: 2.4272]  Perf: 0.5073s per step (258387t/s). Estimated Total Train: 5 days, 6:49:02.638206.
[2026-02-08 19:27:21,620] Train loss 2.3736 at step 23000 with lr 0.00066. [Avg: 2.4149]  Perf: 0.5071s per step (258481t/s). Estimated Total Train: 5 days, 6:46:16.413774.
[2026-02-08 19:35:48,903] Train loss 2.3495 at step 24000 with lr 0.00067. [Avg: 2.3995]  Perf: 0.5073s per step (258381t/s). Estimated Total Train: 5 days, 6:49:13.161907.
[2026-02-08 19:44:16,168] Train loss 2.4229 at step 25000 with lr 0.00069. [Avg: 2.3909]  Perf: 0.5073s per step (258390t/s). Estimated Total Train: 5 days, 6:48:57.570119.
[2026-02-08 19:52:43,389] Train loss 2.3231 at step 26000 with lr 0.00071. [Avg: 2.3806]  Perf: 0.5072s per step (258413t/s). Estimated Total Train: 5 days, 6:48:17.591686.
[2026-02-08 20:01:10,495] Train loss 2.3277 at step 27000 with lr 0.00073. [Avg: 2.3675]  Perf: 0.5071s per step (258471t/s). Estimated Total Train: 5 days, 6:46:34.845271.
[2026-02-08 20:09:37,556] Train loss 2.3459 at step 28000 with lr 0.00074. [Avg: 2.3539]  Perf: 0.5071s per step (258494t/s). Estimated Total Train: 5 days, 6:45:53.670359.
[2026-02-08 20:18:04,603] Train loss 2.4076 at step 29000 with lr 0.00076. [Avg: 2.3489]  Perf: 0.5070s per step (258501t/s). Estimated Total Train: 5 days, 6:45:41.182852.
[2026-02-08 20:26:31,564] Train loss 2.3030 at step 30000 with lr 0.00078. [Avg: 2.3400]  Perf: 0.5070s per step (258545t/s). Estimated Total Train: 5 days, 6:44:23.764215.
[2026-02-08 20:34:58,572] Train loss 2.3783 at step 31000 with lr 0.00080. [Avg: 2.3323]  Perf: 0.5070s per step (258521t/s). Estimated Total Train: 5 days, 6:45:06.671405.
[2026-02-08 20:43:25,437] Train loss 2.3251 at step 32000 with lr 0.00081. [Avg: 2.3497]  Perf: 0.5069s per step (258594t/s). Estimated Total Train: 5 days, 6:42:57.720666.
[2026-02-08 20:51:52,227] Train loss 2.4106 at step 33000 with lr 0.00083. [Avg: 2.3401]  Perf: 0.5068s per step (258632t/s). Estimated Total Train: 5 days, 6:41:50.384560.
[2026-02-08 21:00:19,114] Train loss 2.3463 at step 34000 with lr 0.00085. [Avg: 2.3329]  Perf: 0.5069s per step (258583t/s). Estimated Total Train: 5 days, 6:43:17.517729.
[2026-02-08 21:08:45,908] Train loss 2.3785 at step 35000 with lr 0.00087. [Avg: 2.3290]  Perf: 0.5068s per step (258630t/s). Estimated Total Train: 5 days, 6:41:54.013910.
[2026-02-08 21:17:12,747] Train loss 2.3139 at step 36000 with lr 0.00089. [Avg: 2.3172]  Perf: 0.5068s per step (258607t/s). Estimated Total Train: 5 days, 6:42:33.990412.
[2026-02-08 21:25:39,366] Train loss 2.3415 at step 37000 with lr 0.00090. [Avg: 2.3213]  Perf: 0.5066s per step (258720t/s). Estimated Total Train: 5 days, 6:39:16.064844.
[2026-02-08 21:34:06,111] Train loss 2.3807 at step 38000 with lr 0.00092. [Avg: 2.3114]  Perf: 0.5067s per step (258655t/s). Estimated Total Train: 5 days, 6:41:09.632792.
[2026-02-08 21:42:32,912] Train loss 2.5437 at step 39000 with lr 0.00094. [Avg: 2.3067]  Perf: 0.5068s per step (258627t/s). Estimated Total Train: 5 days, 6:42:00.164108.
[2026-02-08 21:50:59,664] Train loss 2.3114 at step 40000 with lr 0.00096. [Avg: 2.3010]  Perf: 0.5068s per step (258652t/s). Estimated Total Train: 5 days, 6:41:16.175666.
[2026-02-08 21:59:26,364] Train loss 2.3256 at step 41000 with lr 0.00097. [Avg: 2.2973]  Perf: 0.5067s per step (258678t/s). Estimated Total Train: 5 days, 6:40:28.893042.
[2026-02-08 22:07:53,228] Train loss 2.2712 at step 42000 with lr 0.00099. [Avg: 2.2915]  Perf: 0.5069s per step (258595t/s). Estimated Total Train: 5 days, 6:42:56.582980.
[2026-02-08 22:16:19,979] Train loss 2.3528 at step 43000 with lr 0.00097. [Avg: 2.2842]  Perf: 0.5068s per step (258652t/s). Estimated Total Train: 5 days, 6:41:15.212216.
[2026-02-08 22:24:46,755] Train loss 2.2461 at step 44000 with lr 0.00090. [Avg: 2.2729]  Perf: 0.5068s per step (258640t/s). Estimated Total Train: 5 days, 6:41:36.894121.
[2026-02-08 22:33:13,534] Train loss 2.2081 at step 45000 with lr 0.00083. [Avg: 2.2535]  Perf: 0.5068s per step (258638t/s). Estimated Total Train: 5 days, 6:41:40.684190.
[2026-02-08 22:41:40,454] Train loss 2.2656 at step 46000 with lr 0.00076. [Avg: 2.2436]  Perf: 0.5069s per step (258566t/s). Estimated Total Train: 5 days, 6:43:46.784706.
[2026-02-08 22:50:07,217] Train loss 2.2916 at step 47000 with lr 0.00069. [Avg: 2.2476]  Perf: 0.5068s per step (258647t/s). Estimated Total Train: 5 days, 6:41:24.978890.
[2026-02-08 22:58:33,852] Train loss 2.2240 at step 48000 with lr 0.00061. [Avg: 2.2307]  Perf: 0.5066s per step (258711t/s). Estimated Total Train: 5 days, 6:39:30.490408.
[2026-02-08 23:07:00,580] Train loss 2.2434 at step 49000 with lr 0.00054. [Avg: 2.2156]  Perf: 0.5067s per step (258664t/s). Estimated Total Train: 5 days, 6:40:53.316164.
[2026-02-08 23:15:27,315] Train loss 2.1867 at step 50000 with lr 0.00047. [Avg: 2.2059]  Perf: 0.5067s per step (258660t/s). Estimated Total Train: 5 days, 6:41:00.890937.
[2026-02-08 23:23:53,960] Train loss 2.1697 at step 51000 with lr 0.00040. [Avg: 2.1844]  Perf: 0.5066s per step (258707t/s). Estimated Total Train: 5 days, 6:39:39.044294.
[2026-02-08 23:32:20,632] Train loss 2.1747 at step 52000 with lr 0.00033. [Avg: 2.1748]  Perf: 0.5067s per step (258693t/s). Estimated Total Train: 5 days, 6:40:03.907728.
[2026-02-08 23:40:47,341] Train loss 2.1779 at step 53000 with lr 0.00026. [Avg: 2.1623]  Perf: 0.5067s per step (258674t/s). Estimated Total Train: 5 days, 6:40:36.771226.
[2026-02-08 23:49:14,099] Train loss 2.1136 at step 54000 with lr 0.00019. [Avg: 2.1508]  Perf: 0.5068s per step (258649t/s). Estimated Total Train: 5 days, 6:41:21.173158.
[2026-02-08 23:57:40,832] Train loss 2.1287 at step 55000 with lr 0.00012. [Avg: 2.1363]  Perf: 0.5067s per step (258661t/s). Estimated Total Train: 5 days, 6:40:58.789372.
[2026-02-09 00:06:07,518] Train loss 2.1150 at step 56000 with lr 0.00005. [Avg: 2.1269]  Perf: 0.5067s per step (258685t/s). Estimated Total Train: 5 days, 6:40:16.284513.
[2026-02-09 00:12:20,411] Reached deadline. Stopping training ...
[2026-02-09 00:12:21,082] -------------------------------------------------------------
[2026-02-09 00:12:21,082] Finished running job berto4_8h_H100 with total train time: 8:00:09.186582
[2026-02-09 00:12:21,084] Max. Mem allocated: 84.912 GB. Max. Mem reserved: 90.076 GB.
[2026-02-09 00:12:21,084] 4.83e+00 kWh of electricity used for GPU(s) during job.
[2026-02-09 00:12:21,084] -----------------Shutdown complete.--------------------------
